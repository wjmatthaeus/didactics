fn<-"epc_stem_inputs"
paste0(fn,(date()%>%str_remove_all("[ :]")),".csv")
fn<-"epc_stem_inputs_"
paste0(fn,(date()%>%str_remove_all("[ :]")),".csv")
pit_scale %>% dplyr::select(Taxon, Sample,mean_Ap,mean_PsiC, sd_PsiC) %>% write_csv(file = fn)
fn<-"epc_stem_inputs_"
fn<-paste0(fn,(date()%>%str_remove_all("[ :]")),".csv")
pit_scale %>% dplyr::select(Taxon, Sample,mean_Ap,mean_PsiC, sd_PsiC) %>% write_csv(file = fn)
plotdist(noNA, histo=T, demp=T)
descdist(noNA, boot=1000)
for(i in 1:length(pit_scale$l)){
plotname<- paste(pit_scale$Taxon[i],  pit_scale$Sample[i], "fitPlot.pdf")
tempPsiC_array <- unlist(pit_scale$PsiC_array[i])
NAlocs<-is.na(tempPsiC_array)
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))
fw <- fitdist(noNA, distr = "weibull")
fg <- fitdist(noNA, "gamma")
fln <- fitdist(noNA, "lnorm")
fn <- fitdist(noNA, "norm")
plot.legend <- c("Weibull", "normal", "gamma")
denscomp(list(fw, fn, fg), legendtext = plot.legend)
qqcomp(list(fw, fn, fg), legendtext = plot.legend)
cdfcomp(list(fw, fn, fg), legendtext = plot.legend)
ppcomp(list(fw, fn, fg), legendtext = plot.legend)
dev.off()
}
knitr::opts_chunk$set(echo = TRUE)
pkgs <- c("tidyr","dplyr","readr","stringr","ggplot2","fitdistrplus","poweRlaw","ggprism")
vapply(pkgs, library, logical(1), character.only = TRUE, logical.return = TRUE)
data_directory <- "~/Dropbox/bgc_work/stem_bgc/"
f_eudicots<-rlang::as_function(~1.538*(.x)^(-0.402))
#vesselless angiosperms 0.5916x-0.367
f_vesselless_angiosperms<-rlang::as_function(~0.591*(.x)^(-0.367))
#seedless vascular (-P. aquilinum) 0.0419x-0.81
f_seedless_vascular<-rlang::as_function(~0.0419*(.x)^(-0.81))
#conifer stems 0.2307x-0.542
f_conifer<-rlang::as_function(~0.2307*(.x)^(-0.542))
f<-f_eudicots
Fc_cbp <- 0.5
Fc_scalariform <- 1
setwd(data_directory)
pit_scale <- readxl::read_excel(path = "pit_scale_inputs.xlsx",col_names = TRUE)
# colnames(pit_scale)
pit_scale <- pit_scale%>%
mutate(across(c("Mean pit diameter (µm)"  ,
"Pit long axis (µm)" ,
"Pit short axis (µm)"  ,
"Pits per mm tracheid length"    ,
"Pit membrane fractional area"   ,
"Pit membrane area per mm tracheid (mm^2)",
"Number of pits measured",
"Tracheid Diameter (µm)",
"Minimum Tracheid Diameter (µm)",
"Tracheid Length (mm)",
"Minimum Tracheid Length (mm)" ), as.numeric)) %>%
mutate(across(c("Taxon"  ,
"Organ" ,
"Pit type"  ,
"Pit arrangement",
"Sample",
"Upscale Mode"), as.factor))
pit_scale$Group<-"NA"
pit_scale[grep("Corda*", pit_scale$Taxon),]$Group<-"Cordaitalean"
pit_scale[grep("Lepi*",  pit_scale$Taxon),]$Group<-"Lycopsid"
pit_scale[grep("Medu*",  pit_scale$Taxon),]$Group<-"Medullosan"
pit_scale[grep("Psaro*", pit_scale$Taxon),]$Group<-"Psaronius"
pit_scale[grep("Sphen*|Arthr*",pit_scale$Taxon),]$Group<-"Sphenophyte"
pit_scale[grep("Gibl*|Macd*|Thuc*",pit_scale$Taxon),]$Group<-"Extinct Conifer"
pit_scale <- pit_scale %>% mutate(Diameter_sd =  (`Tracheid Diameter (µm)` - `Minimum Tracheid Diameter (µm)`)/2,
l = `Tracheid Length (mm)`,
l_sd = (`Tracheid Length (mm)` - `Minimum Tracheid Length (mm)`)/2,
d_mm = `Tracheid Diameter (µm)`*(1/1000),
d_sd_mm = Diameter_sd*(1/1000),
mean_At = d_mm*pi*`Tracheid Length (mm)`)
unique(pit_scale$`Upscale Mode`)
unique(pit_scale$`Pit type`)
pit_scale <- pit_scale %>%
mutate( Fc = case_when(`Pit type` == "CBP" ~ Fc_cbp,
`Pit type` == "Scalariform" ~ Fc_scalariform))
pit_scale <- pit_scale %>%
mutate(mean_Ap = case_when(
`Upscale Mode` == 'per length' ~
Fc*`Tracheid Length (mm)`*`Pit membrane area per mm tracheid (mm^2)`,
`Upscale Mode` == 'per area' ~
`Pit membrane fractional area`*mean_At*Fc,
.default = as.numeric(NA))) %>%
mutate(backcalculated_Fp = case_when(
`Upscale Mode` == 'per length' ~
mean_Ap/mean_At/Fc )) %>%
mutate(Fp = case_when(
`Upscale Mode` == 'per length' ~ backcalculated_Fp,
`Upscale Mode` == 'per area' ~ `Pit membrane fractional area`,
.default = as.numeric(NA))) %>%
mutate(mean_PsiC_scalar = f(mean_Ap))
ggplot(pit_scale)+geom_histogram(aes(x=Fp, fill = `Upscale Mode`))
##for each variable, setup a column of lists in the dataframe
#tracheid diameter: D
#make list col, each row is a list with output of rnorm
pit_scale$D<-rep(list(item = NA), length(pit_scale$d_mm))
for(i in 1:length(pit_scale$d_mm)){
pit_scale$D[i] <- list(rnorm(n=10000, mean = pit_scale$d_mm[i], sd = pit_scale$d_sd_mm[i]))
}
#check a single distribution, for example D
# for(i in 1:length(pit_scale$d_mm)){
#   print(ggplot()+geom_histogram(aes(x=unlist(pit_scale$D[i]))))
# }
##
#repeat for L
pit_scale$L<-rep(list(item = NA), length(pit_scale$l))
for(i in 1:length(pit_scale$l)){
pit_scale$L[i] <- list(rnorm(n=10000, mean = pit_scale$l[i], sd = pit_scale$l_sd[i]))
}
##
#calculate At array
pit_scale$At_array <-rep(list(item = NA), length(pit_scale$l))
for(i in 1:length(pit_scale$l)){
pit_scale$At_array[i] <- list(unlist(pit_scale$L[i])*unlist(pit_scale$D[i])*pi)
}
##
#calculate Ap array
pit_scale$Ap_array <-rep(list(item = NA), length(pit_scale$l))
for(i in 1:length(pit_scale$l)){
pit_scale$Ap_array[i] <- list(unlist(pit_scale$At_array[i])*pit_scale$Fp[i]*pit_scale$Fc[i])
}
#calculate Psi_c array (this could be passed directly to paleo-bgc)
pit_scale$PsiC_array <-rep(list(item = NA), length(pit_scale$l))
for(i in 1:length(pit_scale$l)){
pit_scale$PsiC_array[i] <- list(
f(unlist(pit_scale$Ap_array[i]))
)
}
pit_scale$mean_PsiC <- as.numeric(NA)
pit_scale$sd_PsiC <- as.numeric(NA)
pit_scale$mean_Ap_array <- as.numeric(NA)
pit_scale$sd_Ap_array <- as.numeric(NA)
for(i in 1:length(pit_scale$l)){
tempPsiC_array <- unlist(pit_scale$PsiC_array[i])
NAlocs<-is.na(tempPsiC_array)
print(paste("there were",length(which(NAlocs)),
"NAs from ", pit_scale$Taxon[i], " ",  pit_scale$Sample[i]))
noNA <- tempPsiC_array[!NAlocs]
temp_fit_norm <- fitdist(noNA, distr = "norm", method = "mle")
pit_scale$mean_PsiC[i] <- temp_fit_norm$estimate["mean"]
pit_scale$sd_PsiC[i] <- temp_fit_norm$sd["mean"]
}
pit_scale %>% group_by(Taxon, `Pit type`)%>%
summarise(mean_PsiC = mean(mean_PsiC),sd_PsiC = mean(sd_PsiC))%>%
dplyr::select(Taxon, Sample,mean_Ap,mean_PsiC, sd_PsiC)
pit_scale %>% group_by(Taxon, `Pit type`)%>%
summarise(mean_PsiC = mean(mean_PsiC),
sd_PsiC = mean(sd_PsiC))%>%
dplyr::select(Taxon,mean_Ap,mean_PsiC, sd_PsiC)
pit_scale %>% group_by(Taxon, `Pit type`)%>%
summarise(mean_PsiC = mean(mean_PsiC),
sd_PsiC = mean(sd_PsiC),
mean_Ap = mean(mean_Ap))%>%
dplyr::select(Taxon,mean_Ap,mean_PsiC, sd_PsiC)
pit_scale %>% group_by(Taxon, `Pit type`)%>%
summarise(mean_PsiC = mean(mean_PsiC),
sd_PsiC = mean(sd_PsiC),
mean_Ap = mean(mean_Ap))%>%
dplyr::select(Taxon,`Pit type`, mean_Ap,mean_PsiC, sd_PsiC)
pit_scale %>% group_by(Group, `Pit type`)%>%
summarise(mean_PsiC = mean(mean_PsiC),
sd_PsiC = mean(sd_PsiC),
mean_Ap = mean(mean_Ap))%>%
dplyr::select(Group,`Pit type`, mean_Ap,mean_PsiC, sd_PsiC)
fn<-"epc_stem_inputs_"
fn<-paste0(fn,(date()%>%str_remove_all("[ :]")),".csv")
pit_scale %>% group_by(Group, `Pit type`)%>%
summarise(mean_PsiC = mean(mean_PsiC),
sd_PsiC = mean(sd_PsiC),
mean_Ap = mean(mean_Ap))%>%
dplyr::select(Group,`Pit type`, mean_Ap,mean_PsiC, sd_PsiC) %>% write_csv(file = fn)
fn<-"epc_stem_inputs_"
fn<-paste0(fn,(date()%>%str_remove_all("[ :]")),".csv")
pit_scale %>% group_by(Group, `Pit type`)%>%
summarise(mean_PsiC = mean(mean_PsiC),
sd_PsiC = mean(sd_PsiC),
mean_Ap = mean(mean_Ap))%>%
dplyr::select(Group,`Pit type`, mean_Ap,mean_PsiC, sd_PsiC) %>% write_csv(file = fn)
pit_scale %>%
dplyr::select(Taxon, Sample, Group,`Pit type`, mean_Ap,mean_PsiC, sd_PsiC) %>% write_csv(file = fn)
fn<-"epc_stem_inputs_"
fn<-paste0(fn,(date()%>%str_remove_all("[ :]")),".csv")
pit_scale %>%
dplyr::select(Taxon, Sample, Group,`Pit type`, mean_Ap,mean_PsiC, sd_PsiC) %>% write_csv(file = fn)
# group_by(Group, `Pit type`)%>%
#   summarise(mean_PsiC = mean(mean_PsiC),
#             sd_PsiC = mean(sd_PsiC),
#             mean_Ap = mean(mean_Ap)) %>%
fn<-paste0("summarized_",fn)
fn
fn<-"epc_stem_inputs_"
fn<-paste0(fn,(date()%>%str_remove_all("[ :]")),".csv")
pit_scale %>%
dplyr::select(Taxon, Sample, Group,`Pit type`, mean_Ap,mean_PsiC, sd_PsiC) %>% write_csv(file = fn)
fn<-paste0("summarized_",fn)
pit_scale %>%  group_by(Group, `Pit type`)%>%
summarise(mean_PsiC = mean(mean_PsiC),
sd_PsiC = mean(sd_PsiC),
mean_Ap = mean(mean_Ap)) %>%
dplyr::select(Group,`Pit type`, mean_Ap,mean_PsiC, sd_PsiC) %>%
write_csv(file = fn)
#gmax calculation set
this_file<-"TRY/31846.txt"
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = FALSE)
# (to do: get phenology trait, complete AusTraits and ChDB integration)
#gmax calculation set
this_file<-"TRY/31846.txt"
v <- read_tsv(file = this_file, col_names = T)
# other traits here
unique(v$TraitName)
# test<- v5 %>% filter(!is.na(TraitID)|DataName%in%c("Longitude","Latitude"))
v_std<- v %>% filter(!is.na(StdValue))
unique(v_std$TraitName)
unique(v_std$DataName)
unique(v_std$DataName)
unique(v$DataName)
"Stomata distribution (surfaces present)"
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = FALSE)
# (to do: get phenology trait, complete AusTraits and ChDB integration)
pkgs <- c("tidyr","dplyr","readr","stringr","ggplot2","readxl","viridis",
"lmerTest","gridExtra","naniar","glmm","cv", "merTools","MuMIn")
vapply(pkgs, library, logical(1), character.only = TRUE, logical.return = TRUE)
'%!in%' <- function(x,y)!('%in%'(x,y))
#'#breaks .rmd for some reason. just run the above line in console
v <- read_tsv(file = "~/Dropbox/traits/TRY/xft_39660.txt", col_names = T)
# try_files_read<-c(try_files_read, this_file)
unique(v$Reference)
head(v, n = 12)
# v %>% select(TraitName,TraitID) %>% unique() %>% write_csv("xft_traits.csv")
length(unique(v$ObsDataID))==length(v$ObsDataID)
v %>% select(DataID,DataName) %>% unique %>% write_csv("xft_datanames.csv")
# try_files_read<-c(try_files_read, this_file)
unique(v$Reference)
head(v, n = 12)
# v %>% select(TraitName,TraitID) %>% unique() %>% write_csv("xft_traits.csv")
length(unique(v$ObsDataID))==length(v$ObsDataID)
v %>% select(DataID,DataName) %>% unique %>% write_csv("xft_datanames.csv")
v %>% dplyr::select(DataID,DataName) %>% unique %>% write_csv("xft_datanames.csv")
ID_NAME <- v %>% filter(!is.na(TraitID)) %>% select(DataID,DataName,TraitName) %>% unique
ID_NAME <- v %>% filter(!is.na(TraitID)) %>% dplyr::select(DataID,DataName,TraitName) %>% unique
ID_NAME <- v %>% filter(!is.na(TraitID)) %>% dplyr::select(DataID,DataName,TraitName) %>% unique
ID_NAME
# length(data_names)
# length(unique(v$ObservationID))
obs_ids <- as.character(unique(v$ObservationID))
for(o in obs_ids){
dn <- v %>% filter(ObservationID == o) %>% select(DataName) %>% unique
data_names[[o]]  <- dn
}
for(o in obs_ids){
dn <- v %>% filter(ObservationID == o) %>% dplyr::select(DataName) %>% unique
data_names[[o]]  <- dn
}
# unique(v$ObservationID)
data_names <- list()
for(o in obs_ids){
dn <- v %>% filter(ObservationID == o) %>% dplyr::select(DataName) %>% unique
data_names[[o]]  <- dn
}
data_names
ID_NAME
print(n=53,ID_NAME)
v
v %>% dplyr::select(TraitID,TraitName) %>% unique
v %>% dplyr::select(TraitID,TraitName) %>% unique %>% print(n=41)
v%>%filter(TraitID == 719)
v%>%filter(TraitID == 719)%>%select(DataName)%>%unique
v%>%filter(TraitID == 719)%>%dplyr::select(DataName)%>%unique
# this_file<-"TRY/"
v <- read_tsv(file = "TRY/34526.txt", col_names = T)
kaack <- read_excel("nph17282-sup-0002-tables1.xlsx",sheet = 2,skip = 6)
kaack <- read_excel("~/Dropbox/traits/TRY/nph17282-sup-0002-tables1.xlsx",sheet = 2,skip = 6)
str(kaack)
kaack <- read_excel("~/Dropbox/traits/TRY/nph17282-sup-0002-tables1.xlsx",sheet = 2,skip = 6)
kaack <- read_excel("~/Dropbox/traits/nph17282-sup-0002-tables1.xlsx",sheet = 2,skip = 6)
str(kaack)
kaack <- kaack %>% rename(p50 = `P50 [MPa]`, p12 = `P12 [MPa]`, p88 = `P88 [MPa]`,
ap = ap, apit = apit, l = l,
se_P50 = `P50 SE [MPa]` , p_range = p12-p88,
npit = NPIT, tpm = `TPM mean [nm]`)
kaack <- kaack %>% rename(p50 = `P50 [MPa]`, p12 = `P12 [MPa]`, p88 = `P88 [MPa]`,
ap = `AP [mm2]`, apit = `APIT [µm]`, l = `LVESSEL[cm]`,
se_P50 = `P50 SE [MPa]` , p_range = p12-p88,
npit = NPIT, tpm = `TPM mean [nm]`)
kaack <- kaack %>% rename(p50 = `P50 [MPa]`, p12 = `P12 [MPa]`, p88 = `P88 [MPa]`,
ap = `AP [mm2]`, apit = `APIT [µm]`, l = `LVESSEL[cm]`,
se_P50 = `P50 SE [MPa]` , p_range =`P12 [MPa]`-`P88 [MPa]`,
npit = NPIT, tpm = `TPM mean [nm]`)
kaack <- kaack %>% rename(p50 = `P50 [MPa]`, p12 = `P12 [MPa]`, p88 = `P88 [MPa]`,
ap = `AP [mm2]`, apit = `APIT [µm]`, l = `LVESSEL[cm]`,
se_P50 = `P50 SE [MPa]` , p_range =`P12 [MPa]`-`P88 [MPa]`,
npit = NPIT, tpm = `TPM mean [nm]`)
kaack <- kaack %>% rename(p50 = `P50 [MPa]`, p12 = `P12 [MPa]`, p88 = `P88 [MPa]`,
ap = `AP [mm2]`, apit = `APIT [µm]`, l = `LVESSEL[cm]`,
se_P50 = `P50 SE [MPa]` ,
npit = NPIT, tpm = `TPM mean [nm]`)
kaack <- kaack %>% rename(p50 = `P50 [MPa]`, p12 = `P12 [MPa]`, p88 = `P88 [MPa]`,
ap = `AP [mm2]`, apit = `APIT [µm]`, l = `LVESSEL[cm]`,
se_P50 = `P50 SE [MPa]` , p_range = p12 - p88,
npit = NPIT, tpm = `TPM mean [nm]`)
kaack <- read_excel("~/Dropbox/traits/nph17282-sup-0002-tables1.xlsx",sheet = 2,skip = 6)
kaack <- read_excel("~/Dropbox/traits/nph17282-sup-0002-tables1.xlsx",sheet = 2,skip = 6)
kaack <- kaack %>% rename(p50 = `P50 [MPa]`, p12 = `P12 [MPa]`, p88 = `P88 [MPa]`,
ap = `AP [mm2]`, apit = `APIT [µm]`, l = `LVESSEL[cm]`,
se_P50 = `P50 SE [MPa]` , p_range = p12 - p88,
npit = NPIT, tpm = `TPM mean [nm]`)
kaack <- kaack %>% rename(p50 = `P50 [MPa]`, p12 = `P12 [MPa]`, p88 = `P88 [MPa]`,
ap = `AP [mm2]`, apit = `APIT [µm]`, l = `LVESSEL[cm]`,
se_P50 = `P50 SE [MPa]` ,
npit = NPIT, tpm = `TPM mean [nm]`) %>%
mutate(p_range = p12 - p88)
kaack
kaack %>% ggplot + geom_boxplot(aes(x = Family, y = se_P50))
v <- read_tsv(file = "~/Dropbox/traits/TRY/xft_39660.txt", col_names = T)
ap_names <- c("Total interconduit pit (membrane) surface area [Ap = Fp x Avessel/tracheid]",
"Xylem water potential at which 50% of conductivity is lost (P50)")
target_names<-tpm_names
p50_name <- c("Xylem water potential at which 50% of conductivity is lost (P50)")
target_names<-p50_name
target <- character()
for(o in obs_ids){
dn <- data_names[[o]]
if(sum(target_names%in%dn$DataName)==length(target_names)){
target[length(target)+1]<-o}
}
target
v_p50 <- v %>% filter(ObservationID %in% as.numeric(obs_p50))
# obs_ap_p50 <- target
## obs_ap_tpm_p50 <- target
# obs_tpm_p50 <- target
obs_p50 <- target
v_p50 <- v %>% filter(ObservationID %in% as.numeric(obs_p50))
v_tpm_p50 %>% group_by(ObservationID)%>%mutate(squished_DataName=str_squish(DataName))%>%
pivot_wider(id_cols = c("ObservationID","AccSpeciesName"), names_from = squished_DataName, values_from = OrigValueStr)%>%
write_csv("wide_xft_p50.csv")
v_tpm_p50 <- v %>% filter(ObservationID %in% as.numeric(obs_tpm_p50))
v_p50 <- v %>% filter(ObservationID %in% as.numeric(obs_p50))
v_p50 %>% group_by(ObservationID)%>%mutate(squished_DataName=str_squish(DataName))%>%
pivot_wider(id_cols = c("ObservationID","AccSpeciesName"), names_from = squished_DataName, values_from = OrigValueStr)%>%
write_csv("wide_xft_ap_p50.csv")
v_p50
v_p50 %>% group_by(ObservationID)%>%mutate(squished_DataName=str_squish(DataName))%>%
pivot_wider(id_cols = c("ObservationID","AccSpeciesName"), names_from = squished_DataName, values_from = OrigValueStr)
v_p50 %>% group_by(ObservationID)%>%mutate(squished_DataName=str_squish(DataName))%>%
pivot_wider(id_cols = c("ObservationID","AccSpeciesName"), names_from = squished_DataName, values_from = OrigValueStr)%>%
write_csv("wide_xft_p50.csv")
getwd()
#this is to load in required packages
pkgs <- c("readr", "ggplot2", "dplyr", "readxl",
"tibble", "tidyr", "stringr",
"PerformanceAnalytics", "psych",
"FactoMineR", "factoextra")
vapply(pkgs, library, logical(1), character.only = TRUE, logical.return = TRUE)
#change the working directory. update the string "/Users.." to contain the
#path to the directory containing this script and your data file
setwd("/Users/willmatthaeus/Dropbox/TCD Postdoc/TERRAFORM/M. Siddiq/")
#change the working directory. update the string "/Users.." to contain the
#path to the directory containing this script and your data file
setwd("/Users/willmatthaeus/Dropbox/TCD Postdoc/TERRAFORM/M. Siddiq/")
#change the working directory. update the string "/Users.." to contain the
#path to the directory containing this script and your data file
setwd("/Users/willmatthaeus/Dropbox/TCD Postdoc/M. Siddiq/")
xrf <- read_excel(path = "STANAST_XRF_GINK.xlsx")
View(xrf)
source("~/Dropbox/TCD Postdoc/M. Siddiq/example_PCA_code.R")
#read in the data
xrf <- read_excel(path = "STANAST_XRF_GINK.xlsx")
input_switch <-"Ant"
#find the group ids from the sample name and make a new column
xrf$locality<-NA
xrf[grep("AST",xrf$SAMPLE),]$locality <- "Astartekløft"
xrf[is.na(xrf$locality),]$locality <- "South Tankrediakløft"
xrf$locality <- as.factor(xrf$locality)
which(is.na(xrf$locality))
#separate out the data columns and the error columns
elements<-xrf[3:32]
elements
element_names <- colnames(elements)
input_switch <-"Ant"
if(input_switch=="Sid"){
#read in the data
xrf <- read_excel(path = "Mastersheet.xlsx")
#find the group ids from the sample name and make a new column
xrf$group<-NA
xrf[grep("CSD",xrf$SAMPLE),]$group <- "new"
xrf[is.na(xrf$group),]$group <- "old"
xrf$group <- as.factor(xrf$group)
#separate out the data columns and the error columns
elements<-xrf[seq(2,76,2)]
element_names <- colnames(elements)
errors<-xrf[seq(3,77,2)]
error_names <- colnames(errors)
}
if(input_switch=="Ant"){
#read in the data
xrf <- read_excel(path = "STANAST_XRF_GINK.xlsx")
#find the group ids from the sample name and make a new column
xrf$locality<-NA
xrf[grep("AST",xrf$SAMPLE),]$locality <- "Astartekløft"
xrf[is.na(xrf$locality),]$locality <- "South Tankrediakløft"
xrf$locality <- as.factor(xrf$locality)
which(is.na(xrf$locality))
#separate out the data columns and the error columns
elements<-xrf[3:32]
element_names <- colnames(elements)
}
##remove columns with zero variance, which causes errors for subsequent analyses
#find zero variance columns
var_nz <- function(x) !is.na(var(x[x != 0]))
varying_elements_map<-apply(elements,2,var_nz)
#update data coulmns and names to only those with varianc
elements <- elements[,varying_elements_map]
element_names <- colnames(elements)
#individual tests of normality
elements %>% ungroup %>%
shapiro_test(element_names) %>%
arrange(variable)
#this is to load in required packages
pkgs <- c("readr", "ggplot2", "dplyr", "readxl",
"tibble", "tidyr", "stringr",
"PerformanceAnalytics", "psych",
"FactoMineR", "factoextra")
vapply(pkgs, library, logical(1), character.only = TRUE, logical.return = TRUE)
#individual tests of normality
elements %>% ungroup %>%
shapiro_test(element_names) %>%
arrange(variable)
#this is to load in required packages
pkgs <- c("readr", "ggplot2", "dplyr", "readxl",
"tibble", "tidyr", "stringr",
"PerformanceAnalytics", "psych",
"FactoMineR", "factoextra","rstatix")
vapply(pkgs, library, logical(1), character.only = TRUE, logical.return = TRUE)
#individual tests of normality
elements %>% ungroup %>%
shapiro_test(element_names) %>%
arrange(variable)
#test of multivariate normality
elements %>% mshapiro_test
#this is the important one!
chart.Correlation(elements)
ele_cor <- cor(elements)
ele_cor
ele_cor <- cor(elements) %>% abs
ele_cor <- cor(elements) %>% abs
which(ele_cor > 0.3)
ele_cor > 0.3)
ele_cor > 0.3
ele_cor_map <- ele_cor > 0.3
ele_cor_map <- ele_cor > 0.3 %>% upper.tri(diag = FALSE)
upper.tri(ele_cor_map,diag = FALSE)
upper.tri(ele_cor_map,diag = FALSE)
ele_cor_map[upper.tri(ele_cor_map,diag = FALSE)]
ele_cor[upper.tri(ele_cor,diag = FALSE)]
ele_cor[upper.tri(ele_cor,diag = FALSE)]<-NA
ele_cor
ele_cor_sig <- apply(ele_cor, 1, function(x){all(abs(x)>0.3)})
ele_cor_sig
ele_cor_sig <- apply(ele_cor, 1, function(x){any(abs(x)>0.3)})
ele_cor_sig
ele_cor_sig <- apply(ele_cor, c(1,2), function(x){any(abs(x)>0.3)})
ele_cor_sig
if(input_switch=="Ant"){
low_cor <- c("Ag","Mo")
#elements with normal-ish distributions based on the histograms
normal <- c("S","Cl","Si","P","K","Ca","Cr")
}
#normal elements
ele_norm <- elements%>%select(normal)#select(!low_cor)
ele_norm_names <- colnames(ele_red)
ele_norm_names <- colnames(ele_norm)
#individual tests of normality ... again
ele_norm %>% ungroup %>%
shapiro_test(ele_norm_names) %>%
arrange(variable)
#test of multivariate normality ... again
ele_norm %>% mshapiro_test
#filtering out the few elements with very low correlations
#this is just going to clarify things in the PCA
ele_cor <- elements%>%select(!low_cor)
ele_cor_names <- colnames(ele_cor)
corr_mat_cor <- ele_cor %>% cor
#Conclusion: the outputs of this PCA are suspect because the underlying
#relationships may not be linear, particularly for the non-normal elements
#you can still use PCA as an exploratory technique, but refer back to the
#correlation matrix when making element-level interpretations
ele_cor<-data.frame(ele_cor)
rownames(ele_cor) <- xrf$SAMPLE
ele_cor
rownames(ele_cor) <- xrf$SAMPLE
#find the group ids from the sample name and make a new column
which(xrf$SAMPLE=="b4-51258-F")
which(xrf$SAMPLE=="b4-51408-F")
xrf[77,]$SAMPLE<-"b4-51408-F_2"
rownames(ele_cor) <- xrf$SAMPLE
xrf[57,]$SAMPLE<-"b4-51258-F_2"
rownames(ele_cor) <- xrf$SAMPLE
res.pca <- PCA(ele_cor, graph = FALSE)
eigenvalues <- res.pca$eig
head(eigenvalues[, 1:2])
#the variance exlained in pc1 and 2 combined is less than 25%,
#add pc3 you get up to 35%
res.pca$var$contrib
fviz_pca_var(res.pca)
fviz_pca_ind(res.pca, label="none", habillage = xrf$group)
fviz_pca_ind(res.pca, label="none", habillage = xrf$locality)
fviz_pca_ind(res.pca, axes = c(1,3), label="none", habillage = xrf$locality)
